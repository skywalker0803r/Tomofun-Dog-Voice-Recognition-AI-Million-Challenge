{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45eeae8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import catboost\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from catboost import CatBoostClassifier\n",
    "import gc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import softmax\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09a21ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d80cde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backbone(self, x):\n",
    "    x = self.module.conv1(x)\n",
    "    x = self.module.bn1(x)\n",
    "    x = self.module.relu(x)\n",
    "\n",
    "    x = self.module.layer1(x)\n",
    "    x = self.module.layer2(x)\n",
    "    x = self.module.layer3(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def preprocessing_Y(file_path):\n",
    "    Y = pd.read_csv(file_path).iloc[:,:]\n",
    "    Y = Y[Y.Filename != 'train_01046']\n",
    "    enc = OneHotEncoder().fit(Y[['Label']])\n",
    "    Y_one_hot = enc.transform(Y[['Label']]).toarray()\n",
    "    Y_one_hot = torch.FloatTensor(Y_one_hot)\n",
    "    print('Y_ont_hot shape',Y_one_hot.shape)\n",
    "    print('Y_df shape',Y.shape)\n",
    "    return Y_one_hot,Y\n",
    "\n",
    "def load_pretrain_senet(model_path):\n",
    "    model = torch.hub.load(\n",
    "        'moskomule/senet.pytorch',\n",
    "        'se_resnet20',\n",
    "        num_classes=6)\n",
    "    model.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    model.fc = nn.Sequential(\n",
    "    nn.Linear(64,64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Dropout(0.5),#三個臭皮匠勝過一個諸葛亮\n",
    "    nn.Linear(64,6))\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0, 1, 2 ,3])#平行運算模式\n",
    "    model.load_state_dict(torch.load(model_path))#載入權重\n",
    "    model.eval()#評估模式\n",
    "    model.fc =  nn.Sequential(model.module.fc,nn.Softmax(dim=1))#取機率\n",
    "    model.backbone = backbone.__get__(model)\n",
    "    return model\n",
    "\n",
    "def get_senet_output(senet,data):\n",
    "    return senet(data)\n",
    "\n",
    "def get_all_senet_output(data):\n",
    "    y = senet(data)\n",
    "    return y.detach().cpu().numpy()\n",
    "\n",
    "def get_X_numpy(X):\n",
    "    X_train_np = np.array([[]])\n",
    "    data_iter = DataLoader(TensorDataset(torch.FloatTensor(X.to(torch.float32))),batch_size=256)\n",
    "    for bx in tqdm(data_iter):\n",
    "        bx = bx[0]\n",
    "        bx = bx.to('cuda:0')\n",
    "        y_hat = get_all_senet_output(bx)\n",
    "        y_hat = softmax(y_hat,axis=1)\n",
    "        if len(X_train_np) == 1:\n",
    "            X_train_np = y_hat\n",
    "        else:\n",
    "            X_train_np = np.vstack((X_train_np,y_hat))\n",
    "    return X_train_np\n",
    "\n",
    "def get_X_numpy_backbone(X):\n",
    "    X_train_np = np.array([[]])\n",
    "    data_iter = DataLoader(TensorDataset(torch.FloatTensor(X.to(torch.float32))),batch_size=64)\n",
    "    for bx in tqdm(data_iter):\n",
    "        bx = bx[0]\n",
    "        bx = bx.to('cuda:0')\n",
    "        y_hat = senet.backbone(bx).detach().cpu().numpy()\n",
    "        y_hat = y_hat.reshape(-1,64*20*40)\n",
    "        if len(X_train_np) == 1:\n",
    "            X_train_np = y_hat\n",
    "        else:\n",
    "            X_train_np = np.vstack((X_train_np,y_hat))\n",
    "    return X_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f270f8b",
   "metadata": {},
   "source": [
    "# 路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4f73e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_path = 'train/meta_train.csv'\n",
    "senet = 'senet20_2021-06-10-00-14-38_random_state5290_validacc_0.925_959訓練240驗證.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba19ce",
   "metadata": {},
   "source": [
    "# load k 個 senet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6c4e5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/moskomule_senet.pytorch_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CifarSEResNet(\n",
       "    (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=1, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=1, out_features=16, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=1, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=1, out_features=16, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=1, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=1, out_features=16, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=2, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=2, out_features=32, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=2, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=2, out_features=32, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=2, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=2, out_features=32, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=4, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=4, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=4, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=6, bias=True)\n",
       "    )\n",
       "    (1): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senet = load_pretrain_senet(senet).to('cuda:0')\n",
    "senet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d51924",
   "metadata": {},
   "source": [
    "# 訓練 和 測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b0d22dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_ont_hot shape torch.Size([1199, 6])\n",
      "Y_df shape (1199, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'Barking',\n",
       " 1: 'Howling',\n",
       " 2: 'Crying',\n",
       " 3: 'COSmoke',\n",
       " 4: 'GlassBreaking',\n",
       " 5: 'Cat'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all = torch.load('X_train_吳啟聖教的方法.pt')\n",
    "X_test_all = torch.load('X_test_吳啟聖教的方法.pt')\n",
    "X_private_all = torch.load('X_private_test_吳啟聖教的方法.pt')\n",
    "\n",
    "Y_train_all,Y_train_df = preprocessing_Y(Y_train_path)\n",
    "map_dict = {}\n",
    "for l in Y_train_df.Label.unique():\n",
    "    map_dict[l] = Y_train_df[Y_train_df.Label==l].sample(1)['Remark'].values[0]\n",
    "map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d00504e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nY_test_all = pd.read_csv('vote_V12_排行榜0.976667.csv') #拿目前分數最高的\\nY_test_all.head(5)\\nvalues = Y_test_all.iloc[:,1:].values.argmax(axis=1) #轉換成one hot格式\\nn_values = np.max(values) + 1\\nnp.eye(n_values)[values][:5]\\nY_test_all.iloc[:,1:] = np.eye(n_values)[values] #轉換成df格式\\nY_test_all\\nY_test_all = torch.FloatTensor(Y_test_all.iloc[:10000,1:].values) #轉換成tensor格式\\nY_test_all,Y_test_all.shape\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Y_test_all = pd.read_csv('vote_V12_排行榜0.976667.csv') #拿目前分數最高的\n",
    "Y_test_all.head(5)\n",
    "values = Y_test_all.iloc[:,1:].values.argmax(axis=1) #轉換成one hot格式\n",
    "n_values = np.max(values) + 1\n",
    "np.eye(n_values)[values][:5]\n",
    "Y_test_all.iloc[:,1:] = np.eye(n_values)[values] #轉換成df格式\n",
    "Y_test_all\n",
    "Y_test_all = torch.FloatTensor(Y_test_all.iloc[:10000,1:].values) #轉換成tensor格式\n",
    "Y_test_all,Y_test_all.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68ac5a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([959, 1, 80, 157])\n",
      "torch.Size([240, 1, 80, 157])\n",
      "0    160\n",
      "1    160\n",
      "2    160\n",
      "3    160\n",
      "5    160\n",
      "4    159\n",
      "dtype: int64\n",
      "0    40\n",
      "1    40\n",
      "2    40\n",
      "3    40\n",
      "4    40\n",
      "5    40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_all, Y_train_all, \n",
    "                                                      test_size=0.2, \n",
    "                                                      random_state=seed,\n",
    "                                                      stratify=Y_train_all)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(pd.DataFrame(y_train.argmax(axis=1)).value_counts())\n",
    "print(pd.DataFrame(y_valid.argmax(axis=1)).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38087791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "trainset = TensorDataset(torch.FloatTensor(X_train.to(torch.float32)),torch.FloatTensor(y_train))\n",
    "vaildset = TensorDataset(torch.FloatTensor(X_valid.to(torch.float32)),torch.FloatTensor(y_valid))\n",
    "train_iter = DataLoader(trainset,batch_size=128,num_workers=4)\n",
    "vaild_iter = DataLoader(vaildset,batch_size=128,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54356008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 80, 157]) cpu\n",
      "torch.Size([128, 6]) cpu\n",
      "torch.Size([128, 64, 20, 40])\n",
      "tensor([[-14.0959, -13.5227, -11.2204,  10.5843,  -9.0482,  -9.6640],\n",
      "        [ -8.4355,  -3.2929,  -4.4402,  -3.5256,  -4.9135,   1.2465],\n",
      "        [ -7.9972,  -5.7093,  -7.3221,  -7.8285,  -7.1900,   4.6640]],\n",
      "       device='cuda:0', grad_fn=<GatherBackward>)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "for bx,by in train_iter:\n",
    "    print(bx.shape,bx.device) # batch,channel,freq,time\n",
    "    print(by.shape,by.device) # batch,n_class\n",
    "    print(senet.backbone(bx.to(device)).size())\n",
    "    print(senet(bx[:3]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a8fd689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "def plot_confusion_matrix(model,data_iter,map_dict=map_dict):\n",
    "    y_true = np.array([])\n",
    "    y_pred = np.array([])\n",
    "    for bx,by in tqdm(data_iter):\n",
    "        bx = bx.to(device)\n",
    "        by = by.to(device)\n",
    "        y_hat = model(bx)\n",
    "        try:\n",
    "            if len(y_true) == 0:\n",
    "                y_true = by.argmax(axis=1).detach().cpu().numpy()\n",
    "                y_pred = y_hat.argmax(axis=1).detach().cpu().numpy()\n",
    "            else:\n",
    "                y_true = np.hstack((y_true,by.argmax(axis=1).detach().cpu().numpy()))\n",
    "                y_pred = np.hstack((y_pred,y_hat.argmax(axis=1).detach().cpu().numpy()))\n",
    "        except:\n",
    "            pass\n",
    "    cm = pd.DataFrame(confusion_matrix(y_pred,y_true))\n",
    "    cm.columns = list(map_dict.values())\n",
    "    acc = accuracy_score(y_pred,y_true)\n",
    "    return cm,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b8262d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9186652763295099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>149</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>158</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Barking  Howling  Crying  COSmoke  GlassBreaking  Cat\n",
       "0      138        4       3        1              0    0\n",
       "1        9      149      18        1              0    1\n",
       "2        3        3     127        0              0    1\n",
       "3        2        1      10      158              4    0\n",
       "4        3        0       0        0            153    2\n",
       "5        5        3       2        0              2  156"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = senet\n",
    "model.eval()\n",
    "cm,acc = plot_confusion_matrix(model.to(device),train_iter)\n",
    "print(acc)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6ed0ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Barking  Howling  Crying  COSmoke  GlassBreaking  Cat\n",
       "0       33        2       0        0              0    0\n",
       "1        2       36       2        0              0    0\n",
       "2        0        2      36        0              0    2\n",
       "3        2        0       0       40              0    0\n",
       "4        0        0       0        0             39    0\n",
       "5        3        0       2        0              1   38"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm,acc = plot_confusion_matrix(model.to(device),vaild_iter)\n",
    "print(acc)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814105b",
   "metadata": {},
   "source": [
    "# 有辦法在提升驗證集的表現嗎?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ae31c",
   "metadata": {},
   "source": [
    "# 接 LogisticRegression 修正senet的弱點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a49a5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 11.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9208333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Barking  Howling  Crying  COSmoke  GlassBreaking  Cat\n",
       "0       33        2       0        0              0    0\n",
       "1        2       36       2        0              0    0\n",
       "2        1        2      36        0              0    2\n",
       "3        1        0       0       39              0    0\n",
       "4        0        0       0        0             39    0\n",
       "5        3        0       2        1              1   38"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np = get_X_numpy(X_train)\n",
    "y_train_np = y_train.detach().numpy().argmax(axis=1)\n",
    "X_valid_np = get_X_numpy(X_valid)\n",
    "y_valid_np = y_valid.detach().numpy().argmax(axis=1)\n",
    "lg = LogisticRegression()\n",
    "lg.fit(X_train_np,y_train_np)\n",
    "y_true = y_valid_np\n",
    "y_pred = lg.predict(X_valid_np )\n",
    "print(accuracy_score(y_pred,y_true))\n",
    "cm = pd.DataFrame(confusion_matrix(y_pred,y_true))\n",
    "cm.columns = list(map_dict.values())\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eacc7e4",
   "metadata": {},
   "source": [
    "# cma-es優化 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67595c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-10 00:17:14,244]\u001b[0m A new study created in memory with name: no-name-a5727f3c-a20c-475e-ac48-e30cba7c8c00\u001b[0m\n",
      " 33%|███▎      | 10/30 [00:00<00:00, 46.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9083333333333333\n",
      "1 0.9125\n",
      "2 0.9166666666666666\n",
      "3 0.9208333333333333\n",
      "4 0.9208333333333333\n",
      "5 0.9208333333333333\n",
      "6 0.9208333333333333\n",
      "7 0.9208333333333333\n",
      "8 0.9208333333333333\n",
      "9 0.9208333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:00<00:00, 48.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.9208333333333333\n",
      "11 0.9208333333333333\n",
      "12 0.925\n",
      "13 0.925\n",
      "14 0.925\n",
      "15 0.925\n",
      "16 0.925\n",
      "17 0.925\n",
      "18 0.925\n",
      "19 0.925\n",
      "20 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 47.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 0.925\n",
      "22 0.925\n",
      "23 0.925\n",
      "24 0.925\n",
      "25 0.925\n",
      "26 0.925\n",
      "27 0.925\n",
      "28 0.925\n",
      "29 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.08324537800723988,\n",
       " 1: 0.6026946650551065,\n",
       " 2: 0.4983260703707777,\n",
       " 3: 0.6081785177929264,\n",
       " 4: 0.5034570042566819,\n",
       " 5: 0.33452565319865263}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "sampler = optuna.samplers.CmaEsSampler()\n",
    "study = optuna.create_study(sampler=sampler,direction='maximize')\n",
    "search_iteration = 30\n",
    "best_acc = 0\n",
    "for epoch in tqdm(range(search_iteration)):\n",
    "    trial = study.ask()\n",
    "    class_weight = {}\n",
    "    for i in [0,1,2,3,4,5]:\n",
    "        class_weight[i] = trial.suggest_uniform(i,0,1)\n",
    "    lg = LogisticRegression(class_weight=class_weight)\n",
    "    lg.fit(X_train_np,y_train_np)\n",
    "    y_true = y_valid_np\n",
    "    y_pred = lg.predict(X_valid_np)\n",
    "    acc = accuracy_score(y_pred,y_true)\n",
    "    if acc>best_acc:\n",
    "        best_acc = acc\n",
    "    print(epoch,best_acc)\n",
    "    study.tell(trial,acc)\n",
    "    \n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1860eb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Barking  Howling  Crying  COSmoke  GlassBreaking  Cat\n",
       "0       33        0       0        0              0    0\n",
       "1        2       37       2        0              0    0\n",
       "2        1        3      36        0              0    2\n",
       "3        1        0       0       40              0    0\n",
       "4        0        0       0        0             39    1\n",
       "5        3        0       2        0              1   37"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np = get_X_numpy(X_train)\n",
    "y_train_np = y_train.detach().numpy().argmax(axis=1)\n",
    "X_valid_np = get_X_numpy(X_valid)\n",
    "y_valid_np = y_valid.detach().numpy().argmax(axis=1)\n",
    "lg = LogisticRegression(class_weight=study.best_params)\n",
    "lg.fit(X_train_np,y_train_np)\n",
    "y_true = y_valid_np\n",
    "y_pred = lg.predict(X_valid_np)\n",
    "acc = accuracy_score(y_pred,y_true)\n",
    "print(acc)\n",
    "cm = pd.DataFrame(confusion_matrix(y_pred,y_true))\n",
    "cm.columns = list(map_dict.values())\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc78656",
   "metadata": {},
   "source": [
    "# 套用private_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86ad72bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 25.91it/s]\n",
      "100%|██████████| 79/79 [00:03<00:00, 23.41it/s]\n"
     ]
    }
   ],
   "source": [
    "X_public_np = get_X_numpy(X_test_all)\n",
    "X_private_np = get_X_numpy(X_private_all)\n",
    "all_test_data = np.vstack((X_public_np,X_private_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dec3578b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d09d5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prob = lg.predict_proba(all_test_data)\n",
    "final_prob.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1994c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>public_00001</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.052423</td>\n",
       "      <td>0.038237</td>\n",
       "      <td>0.014810</td>\n",
       "      <td>0.030362</td>\n",
       "      <td>0.846284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>public_00002</td>\n",
       "      <td>0.015033</td>\n",
       "      <td>0.040344</td>\n",
       "      <td>0.030961</td>\n",
       "      <td>0.011285</td>\n",
       "      <td>0.025663</td>\n",
       "      <td>0.876715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public_00003</td>\n",
       "      <td>0.156129</td>\n",
       "      <td>0.093246</td>\n",
       "      <td>0.168539</td>\n",
       "      <td>0.437445</td>\n",
       "      <td>0.086260</td>\n",
       "      <td>0.058381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>public_00004</td>\n",
       "      <td>0.031156</td>\n",
       "      <td>0.104220</td>\n",
       "      <td>0.073902</td>\n",
       "      <td>0.026852</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>0.702635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public_00005</td>\n",
       "      <td>0.039233</td>\n",
       "      <td>0.078124</td>\n",
       "      <td>0.634467</td>\n",
       "      <td>0.115604</td>\n",
       "      <td>0.078411</td>\n",
       "      <td>0.054160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>private_19996</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.012527</td>\n",
       "      <td>0.034007</td>\n",
       "      <td>0.920264</td>\n",
       "      <td>0.016360</td>\n",
       "      <td>0.008962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>private_19997</td>\n",
       "      <td>0.092505</td>\n",
       "      <td>0.115340</td>\n",
       "      <td>0.125595</td>\n",
       "      <td>0.038888</td>\n",
       "      <td>0.078870</td>\n",
       "      <td>0.548802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>private_19998</td>\n",
       "      <td>0.012468</td>\n",
       "      <td>0.031175</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>0.009012</td>\n",
       "      <td>0.021625</td>\n",
       "      <td>0.901648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>private_19999</td>\n",
       "      <td>0.020564</td>\n",
       "      <td>0.686627</td>\n",
       "      <td>0.237888</td>\n",
       "      <td>0.016004</td>\n",
       "      <td>0.019883</td>\n",
       "      <td>0.019034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>private_20000</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.904420</td>\n",
       "      <td>0.060915</td>\n",
       "      <td>0.007889</td>\n",
       "      <td>0.008916</td>\n",
       "      <td>0.008226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Filename   Barking   Howling    Crying   COSmoke  GlassBreaking  \\\n",
       "0       public_00001  0.017884  0.052423  0.038237  0.014810       0.030362   \n",
       "1       public_00002  0.015033  0.040344  0.030961  0.011285       0.025663   \n",
       "2       public_00003  0.156129  0.093246  0.168539  0.437445       0.086260   \n",
       "3       public_00004  0.031156  0.104220  0.073902  0.026852       0.061237   \n",
       "4       public_00005  0.039233  0.078124  0.634467  0.115604       0.078411   \n",
       "...              ...       ...       ...       ...       ...            ...   \n",
       "29995  private_19996  0.007880  0.012527  0.034007  0.920264       0.016360   \n",
       "29996  private_19997  0.092505  0.115340  0.125595  0.038888       0.078870   \n",
       "29997  private_19998  0.012468  0.031175  0.024073  0.009012       0.021625   \n",
       "29998  private_19999  0.020564  0.686627  0.237888  0.016004       0.019883   \n",
       "29999  private_20000  0.009634  0.904420  0.060915  0.007889       0.008916   \n",
       "\n",
       "          Other  \n",
       "0      0.846284  \n",
       "1      0.876715  \n",
       "2      0.058381  \n",
       "3      0.702635  \n",
       "4      0.054160  \n",
       "...         ...  \n",
       "29995  0.008962  \n",
       "29996  0.548802  \n",
       "29997  0.901648  \n",
       "29998  0.019034  \n",
       "29999  0.008226  \n",
       "\n",
       "[30000 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submit = pd.read_csv('sample_submission.csv')\n",
    "sample_submit.iloc[:30000,1:] = final_prob #三萬筆\n",
    "sample_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7de3300c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 7)\n",
      "0        1.0\n",
      "1        1.0\n",
      "2        1.0\n",
      "3        1.0\n",
      "4        1.0\n",
      "        ... \n",
      "29995    1.0\n",
      "29996    1.0\n",
      "29997    1.0\n",
      "29998    1.0\n",
      "29999    1.0\n",
      "Length: 30000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(sample_submit.shape)\n",
    "print(sample_submit.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cad9f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a71295f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "sample_submit.to_csv(f'submit_seed_{seed}_valid_acc_{acc}_senet_959訓練240驗證_接logistic做最後修正_預測private_test.csv',index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b49f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
