{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45eeae8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import catboost\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from catboost import CatBoostClassifier\n",
    "import gc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import softmax\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d80cde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backbone(self, x):\n",
    "    x = self.module.conv1(x)\n",
    "    x = self.module.bn1(x)\n",
    "    x = self.module.relu(x)\n",
    "\n",
    "    x = self.module.layer1(x)\n",
    "    x = self.module.layer2(x)\n",
    "    x = self.module.layer3(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def preprocessing_Y(file_path):\n",
    "    Y = pd.read_csv(file_path).iloc[:,:]\n",
    "    Y = Y[Y.Filename != 'train_01046']\n",
    "    enc = OneHotEncoder().fit(Y[['Label']])\n",
    "    Y_one_hot = enc.transform(Y[['Label']]).toarray()\n",
    "    Y_one_hot = torch.FloatTensor(Y_one_hot)\n",
    "    print('Y_ont_hot shape',Y_one_hot.shape)\n",
    "    print('Y_df shape',Y.shape)\n",
    "    return Y_one_hot,Y\n",
    "\n",
    "def load_pretrain_senet(model_path):\n",
    "    model = torch.hub.load(\n",
    "        'moskomule/senet.pytorch',\n",
    "        'se_resnet20',\n",
    "        num_classes=6)\n",
    "    model.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    model.fc = nn.Sequential(\n",
    "    nn.Linear(64,64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Dropout(0.5),#三個臭皮匠勝過一個諸葛亮\n",
    "    nn.Linear(64,6))\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0, 1, 2 ,3])#平行運算模式\n",
    "    model.load_state_dict(torch.load(model_path))#載入權重\n",
    "    model.eval()#評估模式\n",
    "    model.fc =  nn.Sequential(model.module.fc,nn.Softmax(dim=1))#取機率\n",
    "    model.backbone = backbone.__get__(model)\n",
    "    return model\n",
    "\n",
    "def get_senet_output(senet,data):\n",
    "    return senet(data)\n",
    "\n",
    "def get_all_senet_output(data):\n",
    "    y = senet(data)\n",
    "    return y.detach().cpu().numpy()\n",
    "\n",
    "def get_X_numpy(X):\n",
    "    X_train_np = np.array([[]])\n",
    "    data_iter = DataLoader(TensorDataset(torch.FloatTensor(X.to(torch.float32))),batch_size=256)\n",
    "    for bx in tqdm(data_iter):\n",
    "        bx = bx[0]\n",
    "        bx = bx.to('cuda:0')\n",
    "        y_hat = get_all_senet_output(bx)\n",
    "        y_hat = softmax(y_hat,axis=1)\n",
    "        if len(X_train_np) == 1:\n",
    "            X_train_np = y_hat\n",
    "        else:\n",
    "            X_train_np = np.vstack((X_train_np,y_hat))\n",
    "    return X_train_np\n",
    "\n",
    "def get_X_numpy_backbone(X):\n",
    "    X_train_np = np.array([[]])\n",
    "    data_iter = DataLoader(TensorDataset(torch.FloatTensor(X.to(torch.float32))),batch_size=64)\n",
    "    for bx in tqdm(data_iter):\n",
    "        bx = bx[0]\n",
    "        bx = bx.to('cuda:0')\n",
    "        y_hat = senet.backbone(bx).detach().cpu().numpy()\n",
    "        y_hat = y_hat.reshape(-1,64*20*40)\n",
    "        if len(X_train_np) == 1:\n",
    "            X_train_np = y_hat\n",
    "        else:\n",
    "            X_train_np = np.vstack((X_train_np,y_hat))\n",
    "    return X_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f270f8b",
   "metadata": {},
   "source": [
    "# 路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4f73e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_path = 'train/meta_train.csv'\n",
    "senet = 'senet20_2021-06-09-01-16-42_random_state529_validacc_0.9132610508757297用訓練資料1199當驗證集.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba19ce",
   "metadata": {},
   "source": [
    "# load k 個 senet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6c4e5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/moskomule_senet.pytorch_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CifarSEResNet(\n",
       "    (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=1, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=1, out_features=16, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=1, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=1, out_features=16, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=1, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=1, out_features=16, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=2, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=2, out_features=32, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=2, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=2, out_features=32, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=2, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=2, out_features=32, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=4, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=4, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=4, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=6, bias=True)\n",
       "    )\n",
       "    (1): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senet = load_pretrain_senet(senet).to('cuda:0')\n",
    "senet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d51924",
   "metadata": {},
   "source": [
    "# 訓練 和 測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b0d22dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_ont_hot shape torch.Size([1199, 6])\n",
      "Y_df shape (1199, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'Barking',\n",
       " 1: 'Howling',\n",
       " 2: 'Crying',\n",
       " 3: 'COSmoke',\n",
       " 4: 'GlassBreaking',\n",
       " 5: 'Cat'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all = torch.load('X_train_吳啟聖教的方法.pt')\n",
    "X_test_all = torch.load('X_test_吳啟聖教的方法.pt')\n",
    "Y_train_all,Y_train_df = preprocessing_Y(Y_train_path)\n",
    "map_dict = {}\n",
    "for l in Y_train_df.Label.unique():\n",
    "    map_dict[l] = Y_train_df[Y_train_df.Label==l].sample(1)['Remark'].values[0]\n",
    "map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d00504e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.]]), torch.Size([10000, 6]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_all = pd.read_csv('vote_V12_排行榜0.976667.csv') #拿目前分數最高的\n",
    "Y_test_all.head(5)\n",
    "values = Y_test_all.iloc[:,1:].values.argmax(axis=1) #轉換成one hot格式\n",
    "n_values = np.max(values) + 1\n",
    "np.eye(n_values)[values][:5]\n",
    "Y_test_all.iloc[:,1:] = np.eye(n_values)[values] #轉換成df格式\n",
    "Y_test_all\n",
    "Y_test_all = torch.FloatTensor(Y_test_all.iloc[:10000,1:].values) #轉換成tensor格式\n",
    "Y_test_all,Y_test_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68ac5a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1, 80, 157])\n",
      "torch.Size([10000, 6])\n",
      "torch.Size([1199, 1, 80, 157])\n",
      "torch.Size([1199, 6])\n",
      "5    3669\n",
      "2    1884\n",
      "1    1566\n",
      "0    1424\n",
      "3     924\n",
      "4     533\n",
      "dtype: int64\n",
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "3    200\n",
      "5    200\n",
      "4    199\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train = X_test_all\n",
    "X_valid = X_train_all\n",
    "y_train = Y_test_all\n",
    "y_valid = Y_train_all\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(pd.DataFrame(y_train.argmax(axis=1)).value_counts())\n",
    "print(pd.DataFrame(y_valid.argmax(axis=1)).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38087791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "trainset = TensorDataset(torch.FloatTensor(X_train.to(torch.float32)),torch.FloatTensor(y_train))\n",
    "vaildset = TensorDataset(torch.FloatTensor(X_valid.to(torch.float32)),torch.FloatTensor(y_valid))\n",
    "train_iter = DataLoader(trainset,batch_size=128,num_workers=4)\n",
    "vaild_iter = DataLoader(vaildset,batch_size=128,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54356008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 80, 157]) cpu\n",
      "torch.Size([32, 6]) cpu\n",
      "torch.Size([32, 64, 20, 40])\n",
      "tensor([[ -8.6800,  -8.0282,  -9.5131,  -8.2114,  -4.1467,   4.0617],\n",
      "        [ -9.1055, -10.6999,  -9.2309,  -8.1376,  -7.3477,   5.1262],\n",
      "        [  2.5682,  -4.9359,  -6.0060,  -6.9322,  -5.8338,  -7.1740]],\n",
      "       device='cuda:0', grad_fn=<GatherBackward>)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "for bx,by in train_iter:\n",
    "    print(bx.shape,bx.device) # batch,channel,freq,time\n",
    "    print(by.shape,by.device) # batch,n_class\n",
    "    print(senet.backbone(bx.to(device)).size())\n",
    "    print(senet(bx[:3]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a8fd689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "def plot_confusion_matrix(model,data_iter,map_dict=map_dict):\n",
    "    y_true = np.array([])\n",
    "    y_pred = np.array([])\n",
    "    for bx,by in tqdm(data_iter):\n",
    "        bx = bx.to(device)\n",
    "        by = by.to(device)\n",
    "        y_hat = model(bx)\n",
    "        try:\n",
    "            if len(y_true) == 0:\n",
    "                y_true = by.argmax(axis=1).detach().cpu().numpy()\n",
    "                y_pred = y_hat.argmax(axis=1).detach().cpu().numpy()\n",
    "            else:\n",
    "                y_true = np.hstack((y_true,by.argmax(axis=1).detach().cpu().numpy()))\n",
    "                y_pred = np.hstack((y_pred,y_hat.argmax(axis=1).detach().cpu().numpy()))\n",
    "        except:\n",
    "            pass\n",
    "    cm = pd.DataFrame(confusion_matrix(y_pred,y_true))\n",
    "    cm.columns = list(map_dict.values())\n",
    "    acc = accuracy_score(y_pred,y_true)\n",
    "    return cm,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b8262d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:12<00:00,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1117</td>\n",
       "      <td>15</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1436</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>1617</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>904</td>\n",
       "      <td>18</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95</td>\n",
       "      <td>37</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>3312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Barking  Howling  Crying  COSmoke  GlassBreaking   Cat\n",
       "0     1117       15      78        3             33   150\n",
       "1      100     1436      89        2              3    49\n",
       "2       50       49    1617        5              0    11\n",
       "3       22       29      27      904             18    60\n",
       "4       40        0       1        1            400    87\n",
       "5       95       37      72        9             79  3312"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = senet\n",
    "model.eval()\n",
    "cm,acc = plot_confusion_matrix(model.to(device),train_iter)\n",
    "print(acc)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6ed0ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9132610508757297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>178</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Barking  Howling  Crying  COSmoke  GlassBreaking  Cat\n",
       "0      183        9       5        1              7    4\n",
       "1        9      178      27        0              0    2\n",
       "2        4       10     165        1              0    5\n",
       "3        2        0       0      196              0    0\n",
       "4        2        0       0        0            192    8\n",
       "5        0        3       3        2              0  181"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm,acc = plot_confusion_matrix(model.to(device),vaild_iter)\n",
    "print(acc)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814105b",
   "metadata": {},
   "source": [
    "# 有辦法在提升驗證集的表現嗎?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ae31c",
   "metadata": {},
   "source": [
    "# 接 LogisticRegression 修正senet的弱點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a49a5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:04<00:00,  8.90it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914095079232694\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>177</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Barking  Howling  Crying  COSmoke  GlassBreaking  Cat\n",
       "0      184        9       5        2              7    4\n",
       "1        8      177      25        0              0    2\n",
       "2        4       11     167        1              0    5\n",
       "3        2        0       0      195              0    0\n",
       "4        2        0       0        0            191    7\n",
       "5        0        3       3        2              1  182"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np = get_X_numpy(X_train)\n",
    "y_train_np = y_train.detach().numpy().argmax(axis=1)\n",
    "X_valid_np = get_X_numpy(X_valid)\n",
    "y_valid_np = y_valid.detach().numpy().argmax(axis=1)\n",
    "lg = LogisticRegression()\n",
    "lg.fit(X_train_np,y_train_np)\n",
    "y_true = y_valid_np\n",
    "y_pred = lg.predict(X_valid_np )\n",
    "print(accuracy_score(y_pred,y_true))\n",
    "cm = pd.DataFrame(confusion_matrix(y_pred,y_true))\n",
    "cm.columns = list(map_dict.values())\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eacc7e4",
   "metadata": {},
   "source": [
    "# cma-es優化 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67595c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 01:32:03,965]\u001b[0m A new study created in memory with name: no-name-0456b1f3-0b08-4e74-be6d-6556ae7aaf87\u001b[0m\n",
      "  3%|▎         | 1/30 [00:01<00:46,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9115929941618015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:03<00:51,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9124270225187656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:05<00:51,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.9132610508757297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:07<00:49,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.9132610508757297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:09<00:50,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.914095079232694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:11<00:47,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.914095079232694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:13<00:46,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.914095079232694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:16<00:47,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:17<00:42,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:20<00:41,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:22<00:39,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [00:24<00:36,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:26<00:34,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [00:28<00:33,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [00:31<00:33,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [00:33<00:30,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [00:34<00:27,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [00:36<00:24,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [00:38<00:21,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [00:40<00:20,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:42<00:18,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.9165971643035863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [00:45<00:16,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 0.9165971643035863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [00:48<00:17,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 0.9165971643035863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [00:50<00:13,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 0.9165971643035863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [00:52<00:10,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 0.9165971643035863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [00:54<00:08,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 0.9165971643035863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [00:56<00:06,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 0.9165971643035863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [00:58<00:04,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 0.9165971643035863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [01:00<00:02,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 0.9165971643035863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:02<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 0.9165971643035863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.32075114426832485,\n",
       " 1: 0.6841917833656804,\n",
       " 2: 0.5465503416337142,\n",
       " 3: 0.5631688623175395,\n",
       " 4: 0.5543402324448308,\n",
       " 5: 0.5645734633271056}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "sampler = optuna.samplers.CmaEsSampler()\n",
    "study = optuna.create_study(sampler=sampler,direction='maximize')\n",
    "search_iteration = 30\n",
    "best_acc = 0\n",
    "for epoch in tqdm(range(search_iteration)):\n",
    "    trial = study.ask()\n",
    "    class_weight = {}\n",
    "    for i in [0,1,2,3,4,5]:\n",
    "        class_weight[i] = trial.suggest_uniform(i,0,1)\n",
    "    lg = LogisticRegression(class_weight=class_weight)\n",
    "    lg.fit(X_train_np,y_train_np)\n",
    "    y_true = y_valid_np\n",
    "    y_pred = lg.predict(X_valid_np)\n",
    "    acc = accuracy_score(y_pred,y_true)\n",
    "    if acc>best_acc:\n",
    "        best_acc = acc\n",
    "    print(epoch,best_acc)\n",
    "    study.tell(trial,acc)\n",
    "    \n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1860eb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:04<00:00,  8.84it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9165971643035863\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>178</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Barking  Howling  Crying  COSmoke  GlassBreaking  Cat\n",
       "0      182        8       4        1              6    2\n",
       "1        8      178      26        0              0    2\n",
       "2        5       11     167        1              0    5\n",
       "3        2        0       0      196              0    0\n",
       "4        2        0       0        0            192    7\n",
       "5        1        3       3        2              1  184"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np = get_X_numpy(X_train)\n",
    "y_train_np = y_train.detach().numpy().argmax(axis=1)\n",
    "X_valid_np = get_X_numpy(X_valid)\n",
    "y_valid_np = y_valid.detach().numpy().argmax(axis=1)\n",
    "lg = LogisticRegression(class_weight=study.best_params)\n",
    "lg.fit(X_train_np,y_train_np)\n",
    "y_true = y_valid_np\n",
    "y_pred = lg.predict(X_valid_np)\n",
    "acc = accuracy_score(y_pred,y_true)\n",
    "print(acc)\n",
    "cm = pd.DataFrame(confusion_matrix(y_pred,y_true))\n",
    "cm.columns = list(map_dict.values())\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc78656",
   "metadata": {},
   "source": [
    "# 套用private_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "86ad72bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_private' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-338af87b8431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_private_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_X_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_private\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_private' is not defined"
     ]
    }
   ],
   "source": [
    "X_public_np = get_X_numpy(X_train)\n",
    "X_private_np = get_X_numpy(X_private)\n",
    "all_test_data = np.vstack((X_public_np,X_private_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d09d5d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_private_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-909c1147b740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_private_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfinal_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_private_np' is not defined"
     ]
    }
   ],
   "source": [
    "final_prob = lg.predict_proba(all_test_data)\n",
    "final_prob.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d1994c88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-e2245d3dc77a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_submit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_submit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msample_submit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_prob' is not defined"
     ]
    }
   ],
   "source": [
    "sample_submit = pd.read_csv('sample_submission.csv')\n",
    "sample_submit.iloc[:30000,1:] = final_prob #三萬筆\n",
    "sample_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7de3300c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 7)\n",
      "0        1.0\n",
      "1        1.0\n",
      "2        1.0\n",
      "3        1.0\n",
      "4        1.0\n",
      "        ... \n",
      "29995    1.0\n",
      "29996    1.0\n",
      "29997    1.0\n",
      "29998    1.0\n",
      "29999    1.0\n",
      "Length: 30000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(sample_submit.shape)\n",
    "print(sample_submit.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0cad9f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9165971643035863"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a71295f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_submit.to_csv(f'submit_valid_acc_{acc}_senet_1199筆當驗證_接logistic做最後修正_預測private_test.csv',index=False)\n",
    "#print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b49f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
