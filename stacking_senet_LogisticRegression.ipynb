{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45eeae8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import catboost\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from catboost import CatBoostClassifier\n",
    "import gc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import softmax\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d80cde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backbone(self, x):\n",
    "    x = self.module.conv1(x)\n",
    "    x = self.module.bn1(x)\n",
    "    x = self.module.relu(x)\n",
    "\n",
    "    x = self.module.layer1(x)\n",
    "    x = self.module.layer2(x)\n",
    "    x = self.module.layer3(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def preprocessing_Y(file_path):\n",
    "    Y = pd.read_csv(file_path).iloc[:,:]\n",
    "    Y = Y[Y.Filename != 'train_01046']\n",
    "    enc = OneHotEncoder().fit(Y[['Label']])\n",
    "    Y_one_hot = enc.transform(Y[['Label']]).toarray()\n",
    "    Y_one_hot = torch.FloatTensor(Y_one_hot)\n",
    "    print('Y_ont_hot shape',Y_one_hot.shape)\n",
    "    print('Y_df shape',Y.shape)\n",
    "    return Y_one_hot,Y\n",
    "\n",
    "def load_pretrain_senet(model_path):\n",
    "    model = torch.hub.load(\n",
    "        'moskomule/senet.pytorch',\n",
    "        'se_resnet20',\n",
    "        num_classes=6)\n",
    "    model.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    model.fc = nn.Sequential(\n",
    "    nn.Linear(64,64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Dropout(0.5),#三個臭皮匠勝過一個諸葛亮\n",
    "    nn.Linear(64,6))\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0, 1, 2 ,3])#平行運算模式\n",
    "    model.load_state_dict(torch.load(model_path))#載入權重\n",
    "    model.eval()#評估模式\n",
    "    model.fc =  nn.Sequential(model.module.fc,nn.Softmax(dim=1))#取機率\n",
    "    model.backbone = backbone.__get__(model)\n",
    "    return model\n",
    "\n",
    "def get_senet_output(senet,data):\n",
    "    return senet(data)\n",
    "\n",
    "def get_all_senet_output(data):\n",
    "    y = senet(data)\n",
    "    return y.detach().cpu().numpy()\n",
    "\n",
    "def get_X_numpy(X):\n",
    "    X_train_np = np.array([[]])\n",
    "    data_iter = DataLoader(TensorDataset(torch.FloatTensor(X.to(torch.float32))),batch_size=256)\n",
    "    for bx in tqdm(data_iter):\n",
    "        bx = bx[0]\n",
    "        bx = bx.to('cuda:0')\n",
    "        y_hat = get_all_senet_output(bx)\n",
    "        y_hat = softmax(y_hat,axis=1)\n",
    "        if len(X_train_np) == 1:\n",
    "            X_train_np = y_hat\n",
    "        else:\n",
    "            X_train_np = np.vstack((X_train_np,y_hat))\n",
    "    return X_train_np\n",
    "\n",
    "def get_X_numpy_backbone(X):\n",
    "    X_train_np = np.array([[]])\n",
    "    data_iter = DataLoader(TensorDataset(torch.FloatTensor(X.to(torch.float32))),batch_size=64)\n",
    "    for bx in tqdm(data_iter):\n",
    "        bx = bx[0]\n",
    "        bx = bx.to('cuda:0')\n",
    "        y_hat = senet.backbone(bx).detach().cpu().numpy()\n",
    "        y_hat = y_hat.reshape(-1,64*20*40)\n",
    "        if len(X_train_np) == 1:\n",
    "            X_train_np = y_hat\n",
    "        else:\n",
    "            X_train_np = np.vstack((X_train_np,y_hat))\n",
    "    return X_train_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f270f8b",
   "metadata": {},
   "source": [
    "# 路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f73e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_path = 'train/meta_train.csv'\n",
    "senet = 'senet20_2021-06-09-01-16-42_random_state529_validacc_0.9132610508757297用訓練資料1199當驗證集.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba19ce",
   "metadata": {},
   "source": [
    "# load k 個 senet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c4e5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/moskomule_senet.pytorch_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CifarSEResNet(\n",
       "    (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=1, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=1, out_features=16, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=1, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=1, out_features=16, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=1, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=1, out_features=16, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=2, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=2, out_features=32, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=2, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=2, out_features=32, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=2, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=2, out_features=32, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=4, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=4, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CifarSEBasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (se): SELayer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=4, out_features=64, bias=False)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=6, bias=True)\n",
       "    )\n",
       "    (1): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senet = load_pretrain_senet(senet).to('cuda:0')\n",
    "senet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d51924",
   "metadata": {},
   "source": [
    "# 訓練 和 測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b0d22dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_ont_hot shape torch.Size([1199, 6])\n",
      "Y_df shape (1199, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'Barking',\n",
       " 1: 'Howling',\n",
       " 2: 'Crying',\n",
       " 3: 'COSmoke',\n",
       " 4: 'GlassBreaking',\n",
       " 5: 'Dishes'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all = torch.load('X_train_吳啟聖教的方法.pt')\n",
    "X_test_all = torch.load('X_test_吳啟聖教的方法.pt')\n",
    "X_private_all = torch.load('X_private_test_吳啟聖教的方法.pt')\n",
    "\n",
    "Y_train_all,Y_train_df = preprocessing_Y(Y_train_path)\n",
    "map_dict = {}\n",
    "for l in Y_train_df.Label.unique():\n",
    "    map_dict[l] = Y_train_df[Y_train_df.Label==l].sample(1)['Remark'].values[0]\n",
    "map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00504e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.]]), torch.Size([10000, 6]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_all = pd.read_csv('vote_V12_排行榜0.976667.csv') #拿目前分數最高的\n",
    "Y_test_all.head(5)\n",
    "values = Y_test_all.iloc[:,1:].values.argmax(axis=1) #轉換成one hot格式\n",
    "n_values = np.max(values) + 1\n",
    "np.eye(n_values)[values][:5]\n",
    "Y_test_all.iloc[:,1:] = np.eye(n_values)[values] #轉換成df格式\n",
    "Y_test_all\n",
    "Y_test_all = torch.FloatTensor(Y_test_all.iloc[:10000,1:].values) #轉換成tensor格式\n",
    "Y_test_all,Y_test_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68ac5a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1, 80, 157])\n",
      "torch.Size([10000, 6])\n",
      "torch.Size([1199, 1, 80, 157])\n",
      "torch.Size([1199, 6])\n",
      "5    3669\n",
      "2    1884\n",
      "1    1566\n",
      "0    1424\n",
      "3     924\n",
      "4     533\n",
      "dtype: int64\n",
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "3    200\n",
      "5    200\n",
      "4    199\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = X_test_all\n",
    "X_valid = X_train_all\n",
    "\n",
    "y_train = Y_test_all\n",
    "y_valid = Y_train_all\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(pd.DataFrame(y_train.argmax(axis=1)).value_counts())\n",
    "print(pd.DataFrame(y_valid.argmax(axis=1)).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38087791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "trainset = TensorDataset(torch.FloatTensor(X_train.to(torch.float32)),torch.FloatTensor(y_train))\n",
    "vaildset = TensorDataset(torch.FloatTensor(X_valid.to(torch.float32)),torch.FloatTensor(y_valid))\n",
    "train_iter = DataLoader(trainset,batch_size=128,num_workers=4)\n",
    "vaild_iter = DataLoader(vaildset,batch_size=128,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54356008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 80, 157]) cpu\n",
      "torch.Size([128, 6]) cpu\n",
      "torch.Size([128, 64, 20, 40])\n",
      "tensor([[ -8.6800,  -8.0282,  -9.5131,  -8.2114,  -4.1467,   4.0617],\n",
      "        [ -9.1055, -10.6999,  -9.2309,  -8.1376,  -7.3477,   5.1262],\n",
      "        [  2.5682,  -4.9359,  -6.0060,  -6.9322,  -5.8338,  -7.1740]],\n",
      "       device='cuda:0', grad_fn=<GatherBackward>)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "for bx,by in train_iter:\n",
    "    print(bx.shape,bx.device) # batch,channel,freq,time\n",
    "    print(by.shape,by.device) # batch,n_class\n",
    "    print(senet.backbone(bx.to(device)).size())\n",
    "    print(senet(bx[:3]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a8fd689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "def plot_confusion_matrix(model,data_iter,map_dict=map_dict):\n",
    "    y_true = np.array([])\n",
    "    y_pred = np.array([])\n",
    "    for bx,by in tqdm(data_iter):\n",
    "        bx = bx.to(device)\n",
    "        by = by.to(device)\n",
    "        y_hat = model(bx)\n",
    "        try:\n",
    "            if len(y_true) == 0:\n",
    "                y_true = by.argmax(axis=1).detach().cpu().numpy()\n",
    "                y_pred = y_hat.argmax(axis=1).detach().cpu().numpy()\n",
    "            else:\n",
    "                y_true = np.hstack((y_true,by.argmax(axis=1).detach().cpu().numpy()))\n",
    "                y_pred = np.hstack((y_pred,y_hat.argmax(axis=1).detach().cpu().numpy()))\n",
    "        except:\n",
    "            pass\n",
    "    cm = pd.DataFrame(confusion_matrix(y_pred,y_true))\n",
    "    cm.columns = list(map_dict.values())\n",
    "    acc = accuracy_score(y_pred,y_true)\n",
    "    return cm,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b8262d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:04<00:00, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Dishes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1117</td>\n",
       "      <td>15</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1436</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>1617</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>904</td>\n",
       "      <td>18</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95</td>\n",
       "      <td>37</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>3312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Barking  Howling  Crying  COSmoke  GlassBreaking  Dishes\n",
       "0     1117       15      78        3             33     150\n",
       "1      100     1436      89        2              3      49\n",
       "2       50       49    1617        5              0      11\n",
       "3       22       29      27      904             18      60\n",
       "4       40        0       1        1            400      87\n",
       "5       95       37      72        9             79    3312"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = senet\n",
    "model.eval()\n",
    "cm,acc = plot_confusion_matrix(model.to(device),train_iter)\n",
    "print(acc)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6ed0ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9132610508757297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Dishes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>178</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Barking  Howling  Crying  COSmoke  GlassBreaking  Dishes\n",
       "0      183        9       5        1              7       4\n",
       "1        9      178      27        0              0       2\n",
       "2        4       10     165        1              0       5\n",
       "3        2        0       0      196              0       0\n",
       "4        2        0       0        0            192       8\n",
       "5        0        3       3        2              0     181"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm,acc = plot_confusion_matrix(model.to(device),vaild_iter)\n",
    "print(acc)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814105b",
   "metadata": {},
   "source": [
    "# 有辦法在提升驗證集的表現嗎?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ae31c",
   "metadata": {},
   "source": [
    "# 接 LogisticRegression 修正senet的弱點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a49a5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 24.94it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 18.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914095079232694\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Dishes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>177</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Barking  Howling  Crying  COSmoke  GlassBreaking  Dishes\n",
       "0      184        9       5        2              7       4\n",
       "1        8      177      25        0              0       2\n",
       "2        4       11     167        1              0       5\n",
       "3        2        0       0      195              0       0\n",
       "4        2        0       0        0            191       7\n",
       "5        0        3       3        2              1     182"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np = get_X_numpy(X_train)\n",
    "y_train_np = y_train.detach().numpy().argmax(axis=1)\n",
    "X_valid_np = get_X_numpy(X_valid)\n",
    "y_valid_np = y_valid.detach().numpy().argmax(axis=1)\n",
    "lg = LogisticRegression()\n",
    "lg.fit(X_train_np,y_train_np)\n",
    "y_true = y_valid_np\n",
    "y_pred = lg.predict(X_valid_np )\n",
    "print(accuracy_score(y_pred,y_true))\n",
    "cm = pd.DataFrame(confusion_matrix(y_pred,y_true))\n",
    "cm.columns = list(map_dict.values())\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eacc7e4",
   "metadata": {},
   "source": [
    "# cma-es優化 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67595c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-09 04:21:13,972]\u001b[0m A new study created in memory with name: no-name-c7f5c536-5352-48cf-9831-b562a3801134\u001b[0m\n",
      "  3%|▎         | 1/30 [00:01<00:31,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9115929941618015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 2/30 [00:02<00:27,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9115929941618015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 3/30 [00:03<00:27,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.9115929941618015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 4/30 [00:03<00:25,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.914095079232694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 5/30 [00:04<00:23,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 6/30 [00:05<00:22,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 7/30 [00:06<00:22,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 8/30 [00:07<00:21,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 9/30 [00:08<00:20,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 10/30 [00:10<00:21,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 11/30 [00:10<00:19,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 12/30 [00:12<00:18,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 13/30 [00:13<00:17,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 14/30 [00:14<00:15,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 15/30 [00:14<00:14,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 16/30 [00:16<00:13,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 17/30 [00:16<00:12,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 18/30 [00:17<00:11,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 19/30 [00:18<00:10,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 20/30 [00:19<00:09,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 21/30 [00:20<00:08,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 22/30 [00:21<00:08,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 23/30 [00:22<00:07,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 24/30 [00:23<00:05,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 25/30 [00:24<00:05,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 26/30 [00:25<00:04,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 27/30 [00:26<00:02,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 28/30 [00:27<00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 29/30 [00:28<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:29<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 0.9157631359466222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.3405323078000035,\n",
       " 1: 0.5178840800640064,\n",
       " 2: 0.34699947639555256,\n",
       " 3: 0.4743215595112902,\n",
       " 4: 0.48186439060507835,\n",
       " 5: 0.5869877481133433}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "sampler = optuna.samplers.CmaEsSampler()\n",
    "study = optuna.create_study(sampler=sampler,direction='maximize')\n",
    "search_iteration = 30\n",
    "best_acc = 0\n",
    "for epoch in tqdm(range(search_iteration)):\n",
    "    trial = study.ask()\n",
    "    class_weight = {}\n",
    "    for i in [0,1,2,3,4,5]:\n",
    "        class_weight[i] = trial.suggest_uniform(i,0,1)\n",
    "    lg = LogisticRegression(class_weight=class_weight)\n",
    "    lg.fit(X_train_np,y_train_np)\n",
    "    y_true = y_valid_np\n",
    "    y_pred = lg.predict(X_valid_np)\n",
    "    acc = accuracy_score(y_pred,y_true)\n",
    "    if acc>best_acc:\n",
    "        best_acc = acc\n",
    "    print(epoch,best_acc)\n",
    "    study.tell(trial,acc)\n",
    "    \n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1860eb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 23.87it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 26.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9157631359466222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Dishes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>178</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Barking  Howling  Crying  COSmoke  GlassBreaking  Dishes\n",
       "0      183        9       5        1              7       2\n",
       "1        8      178      26        0              0       2\n",
       "2        4       10     166        1              0       5\n",
       "3        2        0       0      195              0       0\n",
       "4        2        0       0        0            191       6\n",
       "5        1        3       3        3              1     185"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np = get_X_numpy(X_train)\n",
    "y_train_np = y_train.detach().numpy().argmax(axis=1)\n",
    "X_valid_np = get_X_numpy(X_valid)\n",
    "y_valid_np = y_valid.detach().numpy().argmax(axis=1)\n",
    "lg = LogisticRegression(class_weight=study.best_params)\n",
    "lg.fit(X_train_np,y_train_np)\n",
    "y_true = y_valid_np\n",
    "y_pred = lg.predict(X_valid_np)\n",
    "acc = accuracy_score(y_pred,y_true)\n",
    "print(acc)\n",
    "cm = pd.DataFrame(confusion_matrix(y_pred,y_true))\n",
    "cm.columns = list(map_dict.values())\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc78656",
   "metadata": {},
   "source": [
    "# 套用private_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86ad72bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 25.89it/s]\n",
      "100%|██████████| 79/79 [00:03<00:00, 24.84it/s]\n"
     ]
    }
   ],
   "source": [
    "X_public_np = get_X_numpy(X_train)\n",
    "X_private_np = get_X_numpy(X_private_all)\n",
    "all_test_data = np.vstack((X_public_np,X_private_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dec3578b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d09d5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prob = lg.predict_proba(all_test_data)\n",
    "final_prob.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1994c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Barking</th>\n",
       "      <th>Howling</th>\n",
       "      <th>Crying</th>\n",
       "      <th>COSmoke</th>\n",
       "      <th>GlassBreaking</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>public_00001</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>0.968488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>public_00002</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.010321</td>\n",
       "      <td>0.968521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public_00003</td>\n",
       "      <td>0.853068</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.027109</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>0.096064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>public_00004</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.010323</td>\n",
       "      <td>0.968516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public_00005</td>\n",
       "      <td>0.617983</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>0.242050</td>\n",
       "      <td>0.007242</td>\n",
       "      <td>0.021592</td>\n",
       "      <td>0.090294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>private_19996</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.010905</td>\n",
       "      <td>0.906849</td>\n",
       "      <td>0.012295</td>\n",
       "      <td>0.041668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>private_19997</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.014207</td>\n",
       "      <td>0.030470</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.018006</td>\n",
       "      <td>0.912951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>private_19998</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.010320</td>\n",
       "      <td>0.968522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>private_19999</td>\n",
       "      <td>0.020091</td>\n",
       "      <td>0.027323</td>\n",
       "      <td>0.944184</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.004277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>private_20000</td>\n",
       "      <td>0.020481</td>\n",
       "      <td>0.948867</td>\n",
       "      <td>0.016857</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.011501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Filename   Barking   Howling    Crying   COSmoke  GlassBreaking  \\\n",
       "0       public_00001  0.007827  0.004671  0.007773  0.000901       0.010340   \n",
       "1       public_00002  0.007819  0.004669  0.007770  0.000901       0.010321   \n",
       "2       public_00003  0.853068  0.003930  0.027109  0.003045       0.016785   \n",
       "3       public_00004  0.007821  0.004669  0.007771  0.000901       0.010323   \n",
       "4       public_00005  0.617983  0.020840  0.242050  0.007242       0.021592   \n",
       "...              ...       ...       ...       ...       ...            ...   \n",
       "29995  private_19996  0.010876  0.017408  0.010905  0.906849       0.012295   \n",
       "29996  private_19997  0.022100  0.014207  0.030470  0.002265       0.018006   \n",
       "29997  private_19998  0.007819  0.004669  0.007770  0.000900       0.010320   \n",
       "29998  private_19999  0.020091  0.027323  0.944184  0.002174       0.001952   \n",
       "29999  private_20000  0.020481  0.948867  0.016857  0.000650       0.001644   \n",
       "\n",
       "          Other  \n",
       "0      0.968488  \n",
       "1      0.968521  \n",
       "2      0.096064  \n",
       "3      0.968516  \n",
       "4      0.090294  \n",
       "...         ...  \n",
       "29995  0.041668  \n",
       "29996  0.912951  \n",
       "29997  0.968522  \n",
       "29998  0.004277  \n",
       "29999  0.011501  \n",
       "\n",
       "[30000 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submit = pd.read_csv('sample_submission.csv')\n",
    "sample_submit.iloc[:30000,1:] = final_prob #三萬筆\n",
    "sample_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7de3300c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 7)\n",
      "0        1.0\n",
      "1        1.0\n",
      "2        1.0\n",
      "3        1.0\n",
      "4        1.0\n",
      "        ... \n",
      "29995    1.0\n",
      "29996    1.0\n",
      "29997    1.0\n",
      "29998    1.0\n",
      "29999    1.0\n",
      "Length: 30000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(sample_submit.shape)\n",
    "print(sample_submit.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cad9f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9157631359466222"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a71295f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "sample_submit.to_csv(f'submit_valid_acc_{acc}_senet_1199筆當驗證_接logistic做最後修正_預測private_test.csv',index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b49f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
